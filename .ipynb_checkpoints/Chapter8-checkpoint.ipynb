{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurency\n",
    "\n",
    "- If we run these tasks concurrently we can essentially hide the wait time by running another task in the meantime. It is important to note that this is all still happening on a single thread and still only uses one CPU at a time!\n",
    "\n",
    "- While concurrency isn’t limited to I/O, this is where we see the greatest benefits. In a concurrent program, instead of having your code run serially—that is, from one line to the next—your code is written to handle events, and different parts of your code run when different events happen.\n",
    "\n",
    "- By modeling a program in this way, we are able to deal with the particular event that we are concerned with: I/O wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is the server, save this content to file server.py and run: python server.py\n",
    "from tornado import httpserver\n",
    "from tornado import options\n",
    "from tornado import ioloop\n",
    "from tornado import web\n",
    "from tornado import gen\n",
    "\n",
    "import ujson as json\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "options.define(\"port\", default=8080, help=\"Port to serve on\")\n",
    "\n",
    "\n",
    "class AddMetric(web.RequestHandler):\n",
    "    metric_data = defaultdict(list)\n",
    "\n",
    "    @gen.coroutine\n",
    "    def get(self):\n",
    "        if self.get_argument(\"flush\", False):\n",
    "            json.dump(self.metric_data, open(\"metric_data.json\", \"w+\"))\n",
    "        else:\n",
    "            name = self.get_argument(\"name\")\n",
    "            try:\n",
    "                delay = int(self.get_argument(\"delay\", 1024))\n",
    "            except ValueError:\n",
    "                raise web.HTTPError(400, reason=\"Invalid value for delay\")\n",
    "\n",
    "            start = time.time()\n",
    "            yield gen.Task(ioloop.IOLoop.instance().add_timeout, start + delay / 1000.)\n",
    "            self.write('.')\n",
    "            self.finish()\n",
    "            end = time.time()\n",
    "            self.metric_data[name].append({\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"dt\": end - start,\n",
    "            })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    options.parse_command_line()\n",
    "    port = options.options.port\n",
    "\n",
    "    application = web.Application([\n",
    "        (r\"/add\", AddMetric),\n",
    "    ])\n",
    "\n",
    "    http_server = httpserver.HTTPServer(application)\n",
    "    http_server.listen(port)\n",
    "    print(\"Listening on port: {}\".format(port))\n",
    "    ioloop.IOLoop.instance().start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial Request, one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 500, Time: 55.24573493\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import string\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_urls(base_url, num_urls):\n",
    "    \"\"\"\n",
    "    We add random characters to the end of the URL to break any caching\n",
    "    mechanisms in the requests library or the server\n",
    "    \"\"\"\n",
    "    for i in xrange(num_urls):\n",
    "        yield base_url + \"\".join(random.sample(string.ascii_lowercase, 10))\n",
    "\n",
    "\n",
    "def run_experiment(base_url, num_iter=500):\n",
    "    response_size = 0\n",
    "    for url in generate_urls(base_url, num_iter):\n",
    "        response = requests.get(url)\n",
    "        response_size += len(response.text)\n",
    "    return response_size\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    delay = 100\n",
    "    num_iter = 500\n",
    "    base_url = \"http://localhost:8080/add?name=serial&delay={}&\".format(delay)\n",
    "\n",
    "    start = time.time()\n",
    "    result = run_experiment(base_url, num_iter)\n",
    "    end = time.time()\n",
    "    print(\"Result: {}, Time: {}\".format(result, end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use grequest instead of request to async request, do request another while waiting response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 4.11812591553\n"
     ]
    }
   ],
   "source": [
    "import grequests\n",
    "import string\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_urls(base_url, num_urls):\n",
    "    for i in xrange(num_urls):\n",
    "        yield base_url + \"\".join(random.sample(string.ascii_lowercase, 10))\n",
    "\n",
    "\n",
    "def run_experiment(base_url, num_iter=500):\n",
    "    urls = generate_urls(base_url, num_iter)\n",
    "    requests = (grequests.get(u) for u in urls)\n",
    "    response_futures = grequests.imap(requests, size=100)\n",
    "    response_size = sum(len(r.text) for r in response_futures)\n",
    "    return response_size\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    delay = 100\n",
    "    num_iter = 500\n",
    "\n",
    "    start = time.time()\n",
    "    result = run_experiment(\n",
    "        \"http://127.0.0.1:8080/add?name=grequests&delay={}&\".format(delay),\n",
    "        num_iter)\n",
    "    end = time.time()\n",
    "    print result, (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tornado to even boost the speed more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tornado import ioloop\n",
    "from tornado.httpclient import AsyncHTTPClient\n",
    "\n",
    "from functools import partial\n",
    "import string\n",
    "import random\n",
    "\n",
    "AsyncHTTPClient.configure(\n",
    "    \"tornado.curl_httpclient.CurlAsyncHTTPClient\", max_clients=100)\n",
    "\n",
    "\n",
    "def generate_urls(base_url, num_urls):\n",
    "    for i in xrange(num_urls):\n",
    "        yield base_url + \"\".join(random.sample(string.ascii_lowercase, 10))\n",
    "\n",
    "\n",
    "def fetch_urls(urls, callback):\n",
    "    http_client = AsyncHTTPClient()\n",
    "    urls = list(urls)\n",
    "    responses = []\n",
    "\n",
    "    def _finish_fetch_urls(result):\n",
    "        responses.append(result)\n",
    "        if len(responses) == len(urls):\n",
    "            callback(responses)\n",
    "    for url in urls:\n",
    "        http_client.fetch(url, callback=_finish_fetch_urls)\n",
    "\n",
    "\n",
    "def run_experiment(base_url, num_iter=500, callback=None):\n",
    "    urls = generate_urls(base_url, num_iter)\n",
    "    callback_passthrou = partial(_finish_run_experiment,\n",
    "                                 callback=callback)\n",
    "    fetch_urls(urls, callback_passthrou)\n",
    "\n",
    "\n",
    "def _finish_run_experiment(responses, callback):\n",
    "    response_sum = sum(len(r.body) for r in responses)\n",
    "    print response_sum\n",
    "    callback()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    delay = 100\n",
    "    num_iter = 500\n",
    "    base_url = \"http://127.0.0.1:8080/add?name=tornado_callback&delay={}&\".format(\n",
    "        delay)\n",
    "\n",
    "    _ioloop = ioloop.IOLoop.instance()\n",
    "    _ioloop.add_callback(run_experiment, base_url, num_iter, _ioloop.stop)\n",
    "\n",
    "    start = time.time()\n",
    "    _ioloop.start()\n",
    "    end = time.time()\n",
    "    print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "500 1.07092499733"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use asyncio, standard library from Python 3.4 that unify tornado and grequests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def generate_urls(base_url, num_urls):\n",
    "    for i in range(num_urls):\n",
    "        yield base_url + \"\".join(random.sample(string.ascii_lowercase, 10))\n",
    "\n",
    "\n",
    "def chunked_http_client(num_chunks):\n",
    "    semaphore = asyncio.Semaphore(num_chunks)\n",
    "\n",
    "    @asyncio.coroutine\n",
    "    def http_get(url):\n",
    "        nonlocal semaphore\n",
    "        with (yield from semaphore):\n",
    "            response = yield from aiohttp.request('GET', url)\n",
    "            body = yield from response.content.read()\n",
    "            yield from response.wait_for_close()\n",
    "        return body\n",
    "    return http_get\n",
    "\n",
    "\n",
    "def run_experiment(base_url, num_iter=500):\n",
    "    urls = generate_urls(base_url, num_iter)\n",
    "    http_client = chunked_http_client(100)\n",
    "    tasks = [http_client(url) for url in urls]\n",
    "    responses_sum = 0\n",
    "    for future in asyncio.as_completed(tasks):\n",
    "        data = yield from future\n",
    "        responses_sum += len(data)\n",
    "    return responses_sum\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    loop = asyncio.get_event_loop()\n",
    "    delay = 100\n",
    "    num_iter = 500\n",
    "\n",
    "    start = time.time()\n",
    "    result = loop.run_until_complete(\n",
    "        run_experiment(\n",
    "            \"http://127.0.0.1:8080/add?name=asyncio&delay={}&\".format(delay),\n",
    "            num_iter))\n",
    "    end = time.time()\n",
    "    print(\"{} {}\".format(result, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "500 1.7761478424072266"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
